{"cells":[{"cell_type":"code","source":["dbutils.library.installPyPI('snowflake-connector-python', version = \"2.0.2\")\ndbutils.library.installPyPI(\"azure-storage-blob\", version = \"2.1.0\")\ndbutils.library.installPyPI(\"dill\", version=\"0.2.9\")\ndbutils.library.installPyPI(\"category_encoders\", version=\"2.2.2\")\ndbutils.library.installPyPI(\"lightgbm\", version=\"2.3.0\")\ndbutils.library.installPyPI(\"scipy\", version=\"1.2.1\")\ndbutils.library.installPyPI(\"mlflow\", version=\"1.9.1\")\ndbutils.library.installPyPI(\"pandas\", version=\"0.21.0\")\ndbutils.library.installPyPI('numpy', version=\"1.14.0\")\ndbutils.library.installPyPI(\"scikit-learn\", version=\"0.18.2\")\n\n\ndbutils.library.restartPython()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">PyPI package snowflake-connector-python has been installed already. The previous installed package is PyPI:(snowflake-connector-python)-(2.0.2)-(empty)-(empty). To resolve this issue detach and retach the notebook to create a new environment or rename the package.\nPyPI package azure-storage-blob has been installed already. The previous installed package is PyPI:(azure-storage-blob)-(2.1.0)-(empty)-(empty). To resolve this issue detach and retach the notebook to create a new environment or rename the package.\nPyPI package dill has been installed already. The previous installed package is PyPI:(dill)-(0.2.9)-(empty)-(empty). To resolve this issue detach and retach the notebook to create a new environment or rename the package.\nPyPI package category_encoders has been installed already. The previous installed package is PyPI:(category_encoders)-(2.2.2)-(empty)-(empty). To resolve this issue detach and retach the notebook to create a new environment or rename the package.\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["import pandas as pd\nimport os\nfrom os import path\nfrom scipy.stats import pearsonr, spearmanr\nfrom scipy import stats\nimport numpy as np\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom sklearn.metrics import log_loss, accuracy_score, average_precision_score, confusion_matrix, f1_score, roc_auc_score, mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n# import snowflake.connector\nimport dill\nfrom sklearn.pipeline import Pipeline\nfrom category_encoders import TargetEncoder\nimport mlflow\nfrom sklearn.metrics import make_scorer\n# import pingouin as pg"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["import sklearn\nimport category_encoders\nimport lightgbm\nimport scipy\nprint('pd', pd.__version__)\nprint('sklearn', sklearn.__version__)\nprint('dill', dill.__version__)\nprint('category_encoders', category_encoders.__version__)\nprint('lightgbm', lightgbm.__version__)\nprint('numpy', np.__version__)\nprint('scipy', scipy.__version__)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">pd 0.21.0\nsklearn 0.18.2\ndill 0.2.9\ncategory_encoders 2.2.2\nlightgbm 2.3.0\nnumpy 1.14.0\nscipy 1.2.1\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["if mlflow.get_tracking_uri() != 'databricks':\n  print('update tracking uri')\n  mlflow.set_tracking_uri('databricks')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["def _get_key_metrics(y, y_pred, y_pred_proba):\n  accuracy = accuracy_score(y, y_pred)\n  roc_auc = roc_auc_score(y, y_pred_proba)\n  pr_auc = average_precision_score(y, y_pred)\n  logloss = log_loss(y, y_pred_proba)\n  mae = mean_absolute_error(y, y_pred)\n  conf_max = confusion_matrix(y, y_pred)/len(y)\n\n  return accuracy, roc_auc, pr_auc, logloss, mae\n  \n  \ndef eval_model(y_train, y_train_pred, y_train_pred_proba, y_test, y_test_pred, y_test_pred_proba): \n  y_train = np.reshape(y_train.astype('float').values, (len(y_train), ))\n  y_test = np.reshape(y_test.astype('float').values, (len(y_test), ))\n  \n  print('in y_train, pct of ones', y_train.mean(), 'pct of zeros', 1-y_train.mean())  \n  print('in y_test, pct of ones', y_test.mean(), 'pct of zeros', 1-y_test.mean())\n  \n  residual_std_train = (y_train_pred_proba - y_train).std()\n  y_train_std = y_train.std()\n  \n  residual_std_test = (y_test_pred_proba - y_test).std()\n  y_test_std = y_test.std()\n  \n  accuracy_train, roc_auc_train, pr_auc_train, log_loss_train, mae_train = _get_key_metrics(y_train, y_train_pred, y_train_pred_proba)\n  accuracy_test, roc_auc_test, pr_auc_test, log_loss_test, mae_test = _get_key_metrics(y_test, y_test_pred, y_test_pred_proba)\n  \n  std_shrinking_test = (residual_std_test - y_test_std)/y_test_std\n  std_shrinking_train = (residual_std_train - y_train_std)/y_train_std\n  \n#     logloss_test_pred = log_loss(y_test_reshaped, y_pred_proba)\n#   logloss_baseline = log_loss(y_test_reshaped, np.ones(len(y_pred)))\n#   pred_random = np.random.randint(2, size=len(y_test_reshaped))\n#   logloss_baseline = log_loss(y_test_reshaped, pred_random)\n#   print('logloss_baseline', logloss_baseline)\n#   print('logloss_test_pred', logloss_test_pred)\n  \n#   acc = accuracy_score(y_test_reshaped, y_pred)\n#   f1 = f1_score(y_test_reshaped, y_pred)  \n#   roc_auc = roc_auc_score(y_test_reshaped, y_pred_proba)\n#   print('acc', acc)\n#   print('average_precision_score predicted', average_precision_score(y_test_reshaped, y_pred_proba), 'average_precision_score all zeros', average_precision_score(y_test_reshaped, np.zeros(len(y_pred))))\n#   print('f1 score', f1)\n#   print('roc_auc_score', roc_auc)\n  \n    \n  return std_shrinking_test, std_shrinking_train, \\\n         residual_std_test, y_test_std, residual_std_train, y_train_std, \\\n         accuracy_test, roc_auc_test, pr_auc_test, log_loss_test, mae_test, \\\n         accuracy_train, roc_auc_train, pr_auc_train, log_loss_train, mae_train"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["#### global variables"],"metadata":{}},{"cell_type":"code","source":["number_of_chunks = 10"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## Data loading"],"metadata":{}},{"cell_type":"markdown","source":["#### Real-time query snowflake using complicated sql"],"metadata":{}},{"cell_type":"code","source":["sql_query_train = \"\"\"\nwith daypart_mapping as (\n  SELECT \n    case when day_part = 'late_night' then 'latenight' \n      else DAY_PART\n    END as daypart,\n    MIN(LOCAL_HOUR) as min_hour,\n    MAX(LOCAL_HOUR) as max_hour\n  FROM PRODDB.STATIC.LOOKUP_DAY_PART_MAPPING \n  GROUP BY 1\n),\nflf_targets as (\nSELECT \n  FLF.STARTING_POINT_ID, \n  FLF.STARTING_POINT_NAME, \n  FLF.TIME_OF_DAY as daypart, \n  dp.min_hour,\n  dp.max_hour,\n  FLF.TARGET_IDEAL_FLF, \n  FLF.MIN_TARGET_FLF_RANGE, \n  FLF.MAX_TARGET_FLF_RANGE, \n  FLF.TARGET_CREATED_AT, \n  LEAD(FLF.TARGET_CREATED_AT, 1) OVER (PARTITION BY FLF.STARTING_POINT_ID, FLF.TIME_OF_DAY ORDER BY FLF.TARGET_CREATED_AT) as next, \n  IFNULL(next, '2022-01-01') AS NEXT_TARGET_CREATED_DATE\nFROM STATIC.LOOKUP_TARGET_FLF_BY_REGION flf\nLEFT JOIN daypart_mapping dp \n  on flf.TIME_OF_DAY = dp.DAYPART\n),\nflf_raw as (\nSELECT\n  dd.created_at,\n  dd.DELIVERY_ID,\n  dd.active_date,\n  dd.STORE_STARTING_POINT_ID,\n  dd.SUBMARKET_ID,\n  dd.flf,\n  fces.num_delivered as num_delivered,\n  fces.num_opened as num_opened,\n  sm.LAUNCH_DATE as submarket_launch_date,\n  convert_timezone('UTC', dd.TIMEZONE, dd.CREATED_AT) as created_at_local,\n  TO_DATE(created_at_local) as created_at_local_date,\n  hour(created_at_local) * 2 + floor(minute(created_at_local)/30.0) as window_id,\n  datediff('second', dd.CREATED_AT, dd.ACTUAL_DELIVERY_TIME)/60.0 as asap,\n  dd.DISTINCT_ACTIVE_DURATION/60.0 as dat,\n  datediff('second', dd.DASHER_CONFIRMED_TIME, dd.DASHER_AT_STORE_TIME)/60.0 as d2r,\n  case when datediff('second', dd.QUOTED_DELIVERY_TIME, dd.ACTUAL_DELIVERY_TIME)/60 > 20 then 1 else 0 END as lateness_20_min,\n  flf.daypart,\n  case when dd.flf - flf.MAX_TARGET_FLF_RANGE > 0 then 1 else 0 END as is_flf_above_max,\n  case when dd.flf - flf.TARGET_IDEAL_FLF > 0 then 1 else 0 END as is_flf_above_ideal\nFROM PRODDB.PUBLIC.DIMENSION_DELIVERIES dd \nLEFT JOIN flf_targets flf\n  on dd.STORE_STARTING_POINT_ID = flf.STARTING_POINT_ID\n  AND hour(convert_timezone('UTC', dd.TIMEZONE, dd.created_at)) between flf.min_hour and flf.max_hour\n  AND convert_timezone('UTC', dd.TIMEZONE, dd.created_at) between flf.TARGET_CREATED_AT and flf.NEXT_TARGET_CREATED_DATE\nLEFT JOIN PRODDB.PUBLIC.MAINDB_SUBMARKET sm \n  ON dd.SUBMARKET_ID = sm.ID\nLEFT JOIN public.fact_cx_email_summary fces\n  ON dd.SUBMARKET_ID = fces.SUBMARKET_ID\n  AND convert_timezone('UTC',dd.timezone,\n dateadd('minute',cast(floor(date_part('minute',dd.created_at) / 30) * 30 as int), date_trunc('hour',dd.created_at))\n ) = fces.half_hour_local\nWHERE dd.created_at between '2020-03-16' and '2020-04-27'\n  AND dd.IS_FILTERED_CORE = true \n  AND dd.IS_ASAP = true \n  AND dd.IS_CONSUMER_PICKUP = false \n  AND fulfillment_type != 'merchant_fleet'\n),\n\nflf_raw_grouped as(\nSELECT\n    t.created_at_local_date,\n    t.DAYPART,\n    t.STORE_STARTING_POINT_ID,\n    AVG(t.ASAP) as avg_asap,\n    AVG(t.DAT) as avg_dat,\n    AVG(t.D2R) as avg_d2r,\n    AVG(t.IS_FLF_ABOVE_IDEAL) as avg_is_flf_above_ideal,\n    AVG(t.flf) as avg_flf,\n    AVG(t.num_opened) as avg_num_opened,\n    AVG(t.num_delivered) as avg_num_delivered\nFROM flf_raw t\nGROUP BY t.created_at_local_date, t.DAYPART, t.STORE_STARTING_POINT_ID\n),\nflf_hist as(\nSELECT \n    t1.created_at_local_date,\n    dayofweek(t1.CREATED_AT_LOCAL) as DAY_OF_WEEK,\n    hour(t1.CREATED_AT_LOCAL) as HOUR_OF_DAY,\n    t1.STORE_STARTING_POINT_ID,\n    t1.SUBMARKET_ID,  \n    t1.DAYPART,\n    t1.WINDOW_ID,\n    t1.is_flf_above_ideal\nFROM flf_raw t1\nLEFT JOIN flf_raw_grouped t2\n    ON t1.created_at_local_date = DATEADD(Day, -15, t2.created_at_local_date)\n    AND t1.DAYPART = t2.DAYPART\n    AND t1.STORE_STARTING_POINT_ID = t2.STORE_STARTING_POINT_ID\n)\n\nSELECT *\nFROM flf_hist\nSAMPLE(20)\n\"\"\"\n\n# sql_query_test_verify = \"\"\"\n# CREATE TEMP TABLE CHIZHANG.DAYPART_MAPPING AS (\n#   SELECT \n#     CASE WHEN day_part = 'late_night' THEN 'latenight' \n#       ELSE DAY_PART\n#     END AS daypart,\n#     MIN(LOCAL_HOUR) AS min_hour,\n#     MAX(LOCAL_HOUR) AS max_hour\n#   FROM PRODDB.STATIC.LOOKUP_DAY_PART_MAPPING \n#   GROUP BY 1\n# );\n\n# CREATE temp TABLE CHIZHANG.FLF_TARGETS AS (\n# SELECT \n#   FLF.STARTING_POINT_ID, \n#   FLF.STARTING_POINT_NAME, \n#   FLF.TIME_OF_DAY AS daypart, \n#   dp.min_hour,\n#   dp.max_hour,\n#   FLF.TARGET_IDEAL_FLF, \n#   FLF.MIN_TARGET_FLF_RANGE, \n#   FLF.MAX_TARGET_FLF_RANGE, \n#   FLF.TARGET_CREATED_AT, \n#   LEAD(FLF.TARGET_CREATED_AT, 1) OVER (PARTITION BY FLF.STARTING_POINT_ID, FLF.TIME_OF_DAY ORDER BY FLF.TARGET_CREATED_AT) AS NEXT, \n#   IFNULL(NEXT, '2022-01-01') AS NEXT_TARGET_CREATED_DATE\n# FROM STATIC.LOOKUP_TARGET_FLF_BY_REGION flf\n# LEFT JOIN CHIZHANG.DAYPART_MAPPING dp \n#   ON flf.TIME_OF_DAY = dp.DAYPART\n# );\n    \n# CREATE temp TABLE CHIZHANG.FLF_RAW AS (\n# SELECT\n#   dd.created_at,\n#   dd.DELIVERY_ID,\n#   dd.active_date,\n#   dd.STORE_STARTING_POINT_ID,\n#   dd.SUBMARKET_ID,\n#   dd.flf,\n#   fces.num_delivered AS num_delivered,\n#   fces.num_opened AS num_opened,\n#   sm.LAUNCH_DATE AS submarket_launch_date,\n#   convert_timezone('UTC', dd.TIMEZONE, dd.CREATED_AT) AS created_at_local,\n#   TO_DATE(created_at_local) AS created_at_local_date,\n#   hour(created_at_local) * 2 + floor(minute(created_at_local)/30.0) AS window_id,\n#   datediff('second', dd.CREATED_AT, dd.ACTUAL_DELIVERY_TIME)/60.0 AS asap,\n#   dd.DISTINCT_ACTIVE_DURATION/60.0 AS dat,\n#   datediff('second', dd.DASHER_CONFIRMED_TIME, dd.DASHER_AT_STORE_TIME)/60.0 as d2r,\n#   CASE WHEN datediff('second', dd.QUOTED_DELIVERY_TIME, dd.ACTUAL_DELIVERY_TIME)/60 > 20 THEN 1 ELSE 0 END AS lateness_20_min,\n#   flf.daypart,\n#   CASE WHEN dd.flf - flf.MAX_TARGET_FLF_RANGE > 0 THEN 1 ELSE 0 END AS is_flf_above_max,\n#   CASE WHEN dd.flf - flf.TARGET_IDEAL_FLF > 0 THEN 1 ELSE 0 END AS is_flf_above_ideal\n# FROM PRODDB.PUBLIC.DIMENSION_DELIVERIES dd \n# LEFT JOIN CHIZHANG.FLF_TARGETS flf\n#   ON dd.STORE_STARTING_POINT_ID = flf.STARTING_POINT_ID\n#   AND hour(convert_timezone('UTC', dd.TIMEZONE, dd.created_at)) BETWEEN flf.min_hour AND flf.max_hour\n#   AND convert_timezone('UTC', dd.TIMEZONE, dd.created_at) BETWEEN flf.TARGET_CREATED_AT AND flf.NEXT_TARGET_CREATED_DATE\n# LEFT JOIN PRODDB.PUBLIC.MAINDB_SUBMARKET sm \n#   ON dd.SUBMARKET_ID = sm.ID\n# LEFT JOIN public.fact_cx_email_summary fces\n#   ON dd.SUBMARKET_ID = fces.SUBMARKET_ID\n#   AND convert_timezone('UTC',dd.timezone,\n#  dateadd('minute',CAST(floor(date_part('minute',dd.created_at) / 30) * 30 AS INT), date_trunc('hour',dd.created_at))\n#  ) = fces.half_hour_local\n# //  WHERE CAST(DD.CREATED_AT as DATE) >= dateadd('DAY', -3, TO_TIMESTAMP_NTZ(LOCALTIMESTAMP)) \n#   WHERE dd.created_at BETWEEN '2020-03-16' AND '2020-04-27'\n#   AND CAST(DD.CREATED_AT as DATE) < dateadd('DAY', 0, TO_TIMESTAMP_NTZ(LOCALTIMESTAMP))  \n#   AND dd.IS_FILTERED_CORE = true \n#   AND dd.IS_ASAP = true \n#   AND dd.IS_CONSUMER_PICKUP = false \n#   AND fulfillment_type != 'merchant_fleet'\n# );\n\n# CREATE TEMP TABLE CHIZHANG.FLF_RAW_GROUPED AS(\n# SELECT\n#     t.created_at_local_date,\n#     t.DAYPART,\n#     t.STORE_STARTING_POINT_ID,\n#     AVG(t.ASAP) AS avg_asap,\n#     AVG(t.DAT) AS avg_dat,\n#     AVG(t.D2R) AS avg_d2r,\n#     AVG(t.IS_FLF_ABOVE_IDEAL) AS avg_is_flf_above_ideal,\n#     AVG(t.flf) AS avg_flf,\n#     AVG(t.num_opened) AS avg_num_opened,\n#     AVG(t.num_delivered) AS avg_num_delivered\n# FROM CHIZHANG.FLF_RAW t\n# GROUP BY t.created_at_local_date, t.DAYPART, t.STORE_STARTING_POINT_ID\n# );\n\n# SELECT \n#     -- t1.CREATED_AT,\n#     -- t1.DELIVERY_ID, \n#     -- t1.ACTIVE_DATE, \n#     dayofweek(t1.CREATED_AT_LOCAL) as DAY_OF_WEEK,\n#     hour(t1.CREATED_AT_LOCAL) as HOUR_OF_DAY,\n#     t1.STORE_STARTING_POINT_ID,\n#     t1.SUBMARKET_ID,\n#     -- t1.FLF,\n#     -- t1.NUM_DELIVERED, \n#     -- t1.NUM_OPENED,\n#     -- t1.SUBMARKET_LAUNCH_DATE, \n#     -- t1.CREATED_AT_LOCAL, \n#     -- t1.CREATED_AT_LOCAL_DATE,\n#     -- t1.ASAP, \n#     -- t1.DAT,\n#     -- t1.D2R, \n#     -- t1.LATENESS_20_MIN,\n#     t1.DAYPART,\n#     t1.WINDOW_ID\n#     -- t1.IS_FLF_ABOVE_MAX, \n#     -- t1.IS_FLF_ABOVE_IDEAL,\n#     -- t2.avg_asap,\n#     -- t2.avg_dat,\n#     -- t2.avg_d2r,\n#     -- t2.avg_is_flf_above_ideal,\n#     -- t2.avg_flf,\n#     -- t2.avg_num_delivered,\n#     -- t2.avg_num_opened\n# FROM CHIZHANG.FLF_RAW t1\n# LEFT JOIN CHIZHANG.FLF_RAW_GROUPED t2\n#     ON t1.created_at_local_date = DATEADD(Day, -15, t2.created_at_local_date)\n#     AND t1.DAYPART = t2.DAYPART\n#     AND t1.STORE_STARTING_POINT_ID = t2.STORE_STARTING_POINT_ID\n# SAMPLE(5)\n# \"\"\"\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# full query. complicated query from snowflake\n# toPandas is time-consuming\nscope_name = 'chizhang-scope'\npw_key_name = 'snowflake-password'\nun_key_name = 'snowflake-user'\nuser = dbutils.secrets.get(scope=scope_name, key=un_key_name)\npassword = dbutils.secrets.get(scope=scope_name, key=pw_key_name)\n\n# snowflake connection options\noptions = dict(sfurl=\"doordash.snowflakecomputing.com/\",\n               sfaccount=\"DOORDASH\",\n               sfuser=user,\n               sfpassword=password,\n               sfdatabase=\"PRODDB\",\n               sfschema=\"public\",\n               sfwarehouse=\"ADHOC\")\n\nprint(user)\nprint(password)\n\n# sql_load_table = \"\"\" select * from variance_reduction_flf_train_test \"\"\"\nall_data = spark.read.format(\"snowflake\").options(**options).option(\"query\", sql_query_train).load()\nraw_data = all_data.toPandas()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["#### Query pre-generated table in snowflake using simple sql"],"metadata":{}},{"cell_type":"code","source":["# orig + weather + supply/demand\n# sql_load_pre_gen_table = \"\"\"select * from flf_weather_supply_demand sample (20)\"\"\" \n# orig + weather + supply/demand + pw_flf + incentive\nsql_load_pre_gen_table = \"\"\"select * from flf_weather_supply_demand_hist_incentive sample (20)\"\"\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["# simple query.\n# load pre-generated table from snowflake\n\nuser = dbutils.secrets.get(scope=\"chizhang-scope\", key=\"snowflake-user\")\npassword = dbutils.secrets.get(scope=\"chizhang-scope\", key=\"snowflake-password\")\n\nos.environ['SNOWFLAKE_USER'] = dbutils.secrets.get(scope=\"chizhang-scope\", key=\"snowflake-user\")\nos.environ['SNOWFLAKE_PW'] = dbutils.secrets.get(scope=\"chizhang-scope\", key=\"snowflake-password\")\n\n# snowflake connection options\nparams = dict(\n  user=os.environ['SNOWFLAKE_USER'],\n  password=os.environ['SNOWFLAKE_PW'],\n  account='DOORDASH',\n  database='PRODDB',\n  warehouse='ADHOC',\n  schema='public',\n)\n\n#8min to query 20% of 65mm rows\nwith snowflake.connector.connect(**params) as ctx:\n  raw_data = pd.read_sql(sql_load_pre_gen_table, ctx)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["#### save csv to dbfs"],"metadata":{}},{"cell_type":"code","source":["raw_data_mem_size = raw_data.info(memory_usage='deep')\nprint('raw_data_mem_size', raw_data_mem_size)\n\n#15min to save\n[df_i.to_csv('/dbfs/chizhang/variance_reduction/data/data_weather_supply_demand_flf_incentive_pw_{id}.csv'.format(id=id)) for id, df_i in  enumerate(np.array_split(raw_data, number_of_chunks))]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 13160232 entries, 0 to 13160231\nData columns (total 30 columns):\nCREATED_AT                          datetime64[ns]\nDELIVERY_ID                         int64\nDAY_OF_WEEK                         int64\nHOUR_OF_DAY                         int64\nDAYPART                             object\nSTORE_STARTING_POINT_ID             int64\nSUBMARKET_ID                        int64\nWINDOW_ID                           int64\nIS_FLF_ABOVE_IDEAL                  int64\nPW_HOURLY_AVG_FLF                   float64\nPW_HOURLY_AVG_IS_FLF_ABOVE_IDEAL    float64\nPW_HOURLY_AVG_IS_FLF_ABOVE_MAX      float64\nPW_HOURLY_AVG_DASHER_PAY_OTHER      float64\nHH_TEMPERATURE                      float64\nHH_APPARENT_TEMPERATURE             float64\nHH_PRESSURE                         float64\nHH_HUMIDITY                         float64\nHH_VISIBILITY                       float64\nHH_WIND_SPEED                       float64\nHH_CLOUD_COVER                      float64\nHH_DEWPOINT                         float64\nHH_HOURLY_WEATHER_SUMMARY           object\nHH_PRECIP_INTENSITY                 float64\nHH_PRECIP_PROBABILITY               float64\nHH_ICON                             object\nHH_PRECIP_ACCUMULATION              float64\nHH_PRECIP_TYPE                      object\nPRED_DEMAND                         float64\nACTUAL_DEMAND                       float64\nUNDER_PREDICTED_DEMAND              float64\ndtypes: datetime64[ns](1), float64(18), int64(7), object(4)\nmemory usage: 5.5 GB\nraw_data_mem_size None\nOut[7]: [None, None, None, None, None, None, None, None, None, None]</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["#### load from dbfs"],"metadata":{}},{"cell_type":"code","source":["#2min to load 10 files\ndir = r'/dbfs/chizhang/variance_reduction/data' # use your path\n\nli = []\n\nfor id in range(number_of_chunks):\n  print('chunk id', id)\n  filename = dir + '/data_weather_supply_demand_flf_incentive_pw_'+str(id)+'.csv'\n  df = pd.read_csv(filename, index_col=None)\n  li.append(df)\n\nraw_data = pd.concat(li, axis=0, ignore_index=True)\nprint(raw_data.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">chunk id 0\nchunk id 1\nchunk id 2\nchunk id 3\nchunk id 4\nchunk id 5\n/databricks/python/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2741: DtypeWarning: Columns (22,25,27) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler)\nchunk id 6\nchunk id 7\nchunk id 8\nchunk id 9\n(13160232, 31)\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["df = raw_data.copy()\ndf = df.reindex()\nprint('data size', df.shape)\ndf.columns = map(str.lower, df.columns)\ndf.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div style=\"max-width:1500px;overflow:auto;\">\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unnamed: 0</th>\n      <th>created_at</th>\n      <th>delivery_id</th>\n      <th>day_of_week</th>\n      <th>hour_of_day</th>\n      <th>daypart</th>\n      <th>store_starting_point_id</th>\n      <th>submarket_id</th>\n      <th>window_id</th>\n      <th>is_flf_above_ideal</th>\n      <th>...</th>\n      <th>hh_dewpoint</th>\n      <th>hh_hourly_weather_summary</th>\n      <th>hh_precip_intensity</th>\n      <th>hh_precip_probability</th>\n      <th>hh_icon</th>\n      <th>hh_precip_accumulation</th>\n      <th>hh_precip_type</th>\n      <th>pred_demand</th>\n      <th>actual_demand</th>\n      <th>under_predicted_demand</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2020-04-28 17:45:45.873103</td>\n      <td>564542301</td>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>0</td>\n      <td>...</td>\n      <td>40.97</td>\n      <td>Partly Cloudy</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>partly-cloudy-day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-04-28 17:39:13.605148</td>\n      <td>564526926</td>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>0</td>\n      <td>...</td>\n      <td>40.97</td>\n      <td>Partly Cloudy</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>partly-cloudy-day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020-04-28 17:49:24.791669</td>\n      <td>564550788</td>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>0</td>\n      <td>...</td>\n      <td>40.97</td>\n      <td>Partly Cloudy</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>partly-cloudy-day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020-04-28 17:59:39.664271</td>\n      <td>564575019</td>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>0</td>\n      <td>...</td>\n      <td>40.97</td>\n      <td>Partly Cloudy</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>partly-cloudy-day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2020-04-28 17:39:31.263843</td>\n      <td>564527641</td>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>0</td>\n      <td>...</td>\n      <td>40.97</td>\n      <td>Partly Cloudy</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>partly-cloudy-day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["# drop cols with >50% na\nprint(df.shape)\ndf.columns\ndf_nan = df.isna().sum()/len(df)\nprint(df_nan)\ncols_to_remove = list(df_nan[df_nan > 0.4].index)\nprint('we drop cols with >50% missing values:', cols_to_remove)\ndf = df.drop(cols_to_remove, axis=1)\nprint(df.shape)\n\n\nfor c in ['pw_hourly_avg_flf', 'pw_hourly_avg_is_flf_above_ideal', 'pw_hourly_avg_is_flf_above_max', 'pw_hourly_avg_dasher_pay_other']:\n  df = df[df[c].notna()]\n\nprint(df.isna().sum()/len(df))\nprint(df.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(13160232, 31)\nunnamed: 0                          0.000000\ncreated_at                          0.000000\ndelivery_id                         0.000000\nday_of_week                         0.000000\nhour_of_day                         0.000000\ndaypart                             0.000004\nstore_starting_point_id             0.000000\nsubmarket_id                        0.000000\nwindow_id                           0.000000\nis_flf_above_ideal                  0.000000\npw_hourly_avg_flf                   0.115376\npw_hourly_avg_is_flf_above_ideal    0.115373\npw_hourly_avg_is_flf_above_max      0.115373\npw_hourly_avg_dasher_pay_other      0.115373\nhh_temperature                      0.053842\nhh_apparent_temperature             0.053842\nhh_pressure                         0.053842\nhh_humidity                         0.053842\nhh_visibility                       0.053842\nhh_wind_speed                       0.053842\nhh_cloud_cover                      0.053842\nhh_dewpoint                         0.053842\nhh_hourly_weather_summary           0.053842\nhh_precip_intensity                 0.053842\nhh_precip_probability               0.053842\nhh_icon                             0.053842\nhh_precip_accumulation              0.998414\nhh_precip_type                      0.461473\npred_demand                         0.000000\nactual_demand                       0.000000\nunder_predicted_demand              0.000000\ndtype: float64\nwe drop cols with &gt;50% missing values: [&apos;hh_precip_accumulation&apos;, &apos;hh_precip_type&apos;]\n(13160232, 29)\nunnamed: 0                          0.000000\ncreated_at                          0.000000\ndelivery_id                         0.000000\nday_of_week                         0.000000\nhour_of_day                         0.000000\ndaypart                             0.000000\nstore_starting_point_id             0.000000\nsubmarket_id                        0.000000\nwindow_id                           0.000000\nis_flf_above_ideal                  0.000000\npw_hourly_avg_flf                   0.000000\npw_hourly_avg_is_flf_above_ideal    0.000000\npw_hourly_avg_is_flf_above_max      0.000000\npw_hourly_avg_dasher_pay_other      0.000000\nhh_temperature                      0.060767\nhh_apparent_temperature             0.060767\nhh_pressure                         0.060767\nhh_humidity                         0.060767\nhh_visibility                       0.060767\nhh_wind_speed                       0.060767\nhh_cloud_cover                      0.060767\nhh_dewpoint                         0.060767\nhh_hourly_weather_summary           0.060767\nhh_precip_intensity                 0.060767\nhh_precip_probability               0.060767\nhh_icon                             0.060767\npred_demand                         0.000000\nactual_demand                       0.000000\nunder_predicted_demand              0.000000\ndtype: float64\n(11641856, 29)\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["df.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>Index([&apos;unnamed: 0&apos;, &apos;created_at&apos;, &apos;delivery_id&apos;, &apos;day_of_week&apos;, &apos;hour_of_day&apos;,\n       &apos;daypart&apos;, &apos;store_starting_point_id&apos;, &apos;submarket_id&apos;, &apos;window_id&apos;,\n       &apos;is_flf_above_ideal&apos;, &apos;pw_hourly_avg_flf&apos;,\n       &apos;pw_hourly_avg_is_flf_above_ideal&apos;, &apos;pw_hourly_avg_is_flf_above_max&apos;,\n       &apos;pw_hourly_avg_dasher_pay_other&apos;, &apos;hh_temperature&apos;,\n       &apos;hh_apparent_temperature&apos;, &apos;hh_pressure&apos;, &apos;hh_humidity&apos;,\n       &apos;hh_visibility&apos;, &apos;hh_wind_speed&apos;, &apos;hh_cloud_cover&apos;, &apos;hh_dewpoint&apos;,\n       &apos;hh_hourly_weather_summary&apos;, &apos;hh_precip_intensity&apos;,\n       &apos;hh_precip_probability&apos;, &apos;hh_icon&apos;, &apos;pred_demand&apos;, &apos;actual_demand&apos;,\n       &apos;under_predicted_demand&apos;],\n      dtype=&apos;object&apos;)</div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["## Feature creating"],"metadata":{}},{"cell_type":"code","source":["# combine real-time features with historical aggregated features\n# features_cat = ['day_of_week', 'hour_of_day', 'STORE_STARTING_POINT_ID', 'SUBMARKET_ID', 'LATENESS_20_MIN', 'DAYPART', '30min'] #30 min, sp, submarket, ->market level feats\n# historical aggregated features := avg(feat_values) over SP_ID/(DATE_LOCAL-15days)/DAYPART units (i.e., 14 days ago) \n# features_num = ['AVG_ASAP', 'AVG_DAT', 'AVG_D2R', 'AVG_FLF', 'AVG_IS_FLF_ABOVE_IDEAL']\n\n# features_cat = ['day_of_week', 'hour_of_day', 'store_starting_point_id', 'submarket_id', 'daypart', 'window_id'] #30 min, sp, submarket, ->market level feats\n# # features_num = ['AVG_ASAP', 'AVG_DAT', 'AVG_D2R', 'AVG_FLF', 'AVG_IS_FLF_ABOVE_IDEAL', 'AVG_NUM_DELIVERED', 'AVG_NUM_OPENED']\n# features_num = []\n\n# features_cat = ['day_of_week', 'hour_of_day', 'store_starting_point_id', 'submarket_id', 'daypart', 'window_id', \\\n#                'hh_hourly_weather_summary',  'hh_precip_type', 'hh_icon']\n# features_num = ['hh_temperature', 'hh_apparent_temperature', 'hh_pressure', 'hh_humidity', 'hh_dewpoint', 'hh_visibility', \\\n#                 'hh_wind_speed', 'hh_cloud_cover', 'hh_dewpoint', 'hh_precip_intensity', 'hh_precip_probability', \\\n#                 'pred_demand']\n\n\nfeatures_orig = ['day_of_week', 'hour_of_day', 'daypart', 'store_starting_point_id', 'submarket_id', 'window_id']\nfeatures_weather = ['hh_temperature', 'hh_apparent_temperature', 'hh_pressure', 'hh_humidity', 'hh_visibility', \\\n                    'hh_wind_speed', 'hh_cloud_cover', 'hh_dewpoint', 'hh_precip_intensity', 'hh_precip_probability',\\\n                    'hh_hourly_weather_summary', 'hh_icon']\nfeatures_supply_demand = ['pred_demand', 'actual_demand', 'under_predicted_demand']\nfeatures_hist_flf = ['pw_hourly_avg_flf', 'pw_hourly_avg_is_flf_above_ideal', 'pw_hourly_avg_is_flf_above_max']\nfeatures_incentive = ['pw_hourly_avg_dasher_pay_other']\n\nfeatures_type = { \"day_of_week\" : \"category\",\n                  \"hour_of_day\" : \"category\",\n                  'daypart'     : \"category\",\n                 \n                  'hh_hourly_weather_summary': \"category\", #or target_encode\n                  'hh_icon'     : \"category\",#or target_encode\n\n                  'store_starting_point_id' : \"target_encode\", \n                  'submarket_id' : \"target_encode\",   \n                  'window_id'    : \"target_encode\",\n\n                  'hh_temperature' : \"numerical\", \n                  'hh_apparent_temperature' : \"numerical\", \n                  'hh_pressure'    : \"numerical\",\n                  'hh_humidity'    : \"numerical\",\n                  'hh_visibility'  : \"numerical\",\n                  'hh_wind_speed'  : \"numerical\",\n                  'hh_cloud_cover' : \"numerical\", \n                  'hh_dewpoint'    : \"numerical\",\n                  'hh_precip_intensity'   : \"numerical\",\n                  'hh_precip_probability' : \"numerical\",\n                 \n                  'pw_hourly_avg_flf' : \"numerical\", \n                  'pw_hourly_avg_is_flf_above_ideal': \"numerical\",\n                  'pw_hourly_avg_is_flf_above_max': \"numerical\",\n                 \n                  'pw_hourly_avg_dasher_pay_other' : \"numerical\",\n                 }\n\nfor f in features_type:\n  if features_type.get(f) == 'category' or features_type.get(f) == 'target_encode':\n    df[f] = df[f].astype('category')\n  elif features_type.get(f) == 'numerical':\n    df[f] = df[f].astype('float')\n  else:\n    raise('wrong feature type')\n    \nfeatures_target_encode = [k for k,v in features_type.items() if v == 'target_encode']\n\nfeatures = features_orig + features_weather + features_supply_demand + features_hist_flf + features_incentive\nmetrics = 'is_flf_above_ideal'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["len(features)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">22</span><span class=\"ansired\">]: </span>25</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["## Eval raw correlation"],"metadata":{}},{"cell_type":"code","source":["df.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">13</span><span class=\"ansired\">]: </span>Index([&apos;unnamed: 0&apos;, &apos;created_at&apos;, &apos;delivery_id&apos;, &apos;day_of_week&apos;, &apos;hour_of_day&apos;,\n       &apos;daypart&apos;, &apos;store_starting_point_id&apos;, &apos;submarket_id&apos;, &apos;window_id&apos;,\n       &apos;is_flf_above_ideal&apos;, &apos;pw_hourly_avg_flf&apos;,\n       &apos;pw_hourly_avg_is_flf_above_ideal&apos;, &apos;pw_hourly_avg_is_flf_above_max&apos;,\n       &apos;pw_hourly_avg_dasher_pay_other&apos;, &apos;hh_temperature&apos;,\n       &apos;hh_apparent_temperature&apos;, &apos;hh_pressure&apos;, &apos;hh_humidity&apos;,\n       &apos;hh_visibility&apos;, &apos;hh_wind_speed&apos;, &apos;hh_cloud_cover&apos;, &apos;hh_dewpoint&apos;,\n       &apos;hh_hourly_weather_summary&apos;, &apos;hh_precip_intensity&apos;,\n       &apos;hh_precip_probability&apos;, &apos;hh_icon&apos;, &apos;pred_demand&apos;, &apos;actual_demand&apos;,\n       &apos;under_predicted_demand&apos;],\n      dtype=&apos;object&apos;)</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["## Plot raw correlation"],"metadata":{}},{"cell_type":"code","source":["def plot_corr(df):\n  te = TargetEncoder(cols=features_target_encode)\n  df_corr = te.fit_transform(df[features], df[metrics])\n#   print(df_corr)\n  df_corr['is_flf_above_ideal'] = df[metrics]\n  print(df_corr.corr()['is_flf_above_ideal'].abs().sort_values(ascending=False))\n\nplot_corr(df)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">is_flf_above_ideal                  1.000000\npw_hourly_avg_is_flf_above_ideal    0.329422\nstore_starting_point_id             0.316617\npw_hourly_avg_is_flf_above_max      0.283884\nsubmarket_id                        0.231601\nwindow_id                           0.204695\npw_hourly_avg_flf                   0.194348\nunder_predicted_demand              0.150332\npw_hourly_avg_dasher_pay_other      0.103802\nhh_visibility                       0.049783\nhh_precip_probability               0.038691\nhh_wind_speed                       0.036426\nhh_pressure                         0.033314\nhh_apparent_temperature             0.031012\nactual_demand                       0.026766\nhh_temperature                      0.025377\nhh_humidity                         0.025292\nhh_precip_intensity                 0.014922\nhh_cloud_cover                      0.012332\nhh_dewpoint                         0.010239\npred_demand                         0.002703\nName: is_flf_above_ideal, dtype: float64\n</div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["## Train/test data preparing"],"metadata":{}},{"cell_type":"code","source":["from datetime import datetime, timedelta\n\ndf['created_at'] = pd.to_datetime(df['created_at'])\ndate_train_end = df['created_at'].dt.date.max() - timedelta(weeks=1)\ndate_train_start = date_train_end - timedelta(weeks=5)\n\ntrain_index = df[(df['created_at'] < str(date_train_end)) & (df['created_at'] >= str(date_train_start))].index\ntest_index = df[df['created_at'] >= str(date_train_end)].index\n\nprint('training period:', df.loc[train_index]['created_at'].min(), df.loc[train_index]['created_at'].max())\nprint('testing period:', df.loc[test_index]['created_at'].min(), df.loc[test_index]['created_at'].max())\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">training period: 2020-04-27 00:00:00.025144 2020-05-21 23:59:59.818855\ntesting period: 2020-05-22 00:00:00.137764 2020-05-29 23:59:59.805666\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["# check train and test index do not intersects\nassert len(train_index.intersection(test_index))==0, 'data leakage'\n# check if training and testing data has 7 days a week\nassert df.loc[test_index]['day_of_week'].nunique() == 7, 'testing data does not have 7 days a week'\nassert df.loc[train_index]['day_of_week'].nunique() == 7, 'training data does not have 7 days a week'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["### Create pipeline & train"],"metadata":{}},{"cell_type":"markdown","source":["### random search mlflow"],"metadata":{}},{"cell_type":"code","source":["mlflow.set_experiment('/Shared/Experiments/variance_reduction_flf')\n\ndef train_mlflow_randomsearch(features, run_name):\n  with mlflow.start_run(run_name=run_name):\n\n      X_train = df.loc[train_index, features]\n      y_train = df.loc[train_index, metrics]\n\n      X_test = df.loc[test_index, features]\n      y_test = df.loc[test_index, metrics]\n\n      print(\"x_train shape\", X_train.shape, 'y_train shape', y_train.shape)\n      print(\"x_test shape\", X_test.shape, 'y_test shape', y_test.shape)\n\n      \n      # target encoding\n      teppl = TargetEncoder(cols=features_target_encode)\n      # clf\n      clfppl = LGBMClassifier()\n\n      # random search\n      # best for orig+weather+supply_demand\n      # {'clf__boosting_type': 'gbdt', 'clf__learning_rate': 0.10799590819985533, 'clf__num_leaves': 476}\n      # {'clf__boosting_type': 'gbdt', 'clf__learning_rate': 0.10442678580364907, 'clf__num_leaves': 411} +weather\n      # {'clf__boosting_type': 'gbdt', 'clf__learning_rate': 0.08908617527882136, 'clf__num_leaves': 491} +weather+supply/demand\n      \n      randomParams = {\n          'clf__learning_rate': stats.uniform(0.01, 0.1), \n          'clf__num_leaves': stats.randint(16, 512),\n          'clf__boosting_type' : ['gbdt', 'dart', 'goss']    \n      }\n  \n      \n      ppl = Pipeline([('target_encode', teppl), ('clf', clfppl)])\n\n      random_search = RandomizedSearchCV(ppl, randomParams, n_jobs=-1, verbose=2, n_iter=50)\n      random_search.fit(X_train, y_train)\n      \n      y_test_pred = random_search.predict(X_test)\n      y_test_pred_proba = random_search.predict_proba(X_test)[:,1]\n      \n      y_train_pred = random_search.predict(X_train)\n      y_train_pred_proba = random_search.predict_proba(X_train)[:,1]\n      \n\n      # metrics\n      std_shrinking_test, std_shrinking_train, \\\n           residual_std_test, y_test_std, residual_std_train, y_train_std, \\\n           accuracy_test, roc_auc_test, pr_auc_test, log_loss_test, mae_test, \\\n           accuracy_train, roc_auc_train, pr_auc_train, log_loss_train, mae_train = eval_model(y_train, y_train_pred, y_train_pred_proba, y_test, y_test_pred, y_test_pred_proba)\n\n      print('best param', random_search.best_params_)\n\n      mlflow.set_tag('features', features)\n\n      print(\"Test Log Loss: {0}\".format(log_loss_test))\n      print(\"Train Log Loss: {0}\".format(log_loss_train))\n\n      print(\"Test Accuracy Score: {0}\".format(accuracy_test))\n      print(\"Train Accuracy Score: {0}\".format(accuracy_train))\n\n      print(\"Test ROC AUC: {0}\".format(roc_auc_test))\n      print(\"Train ROC AUC: {0}\".format(roc_auc_train))\n\n      print(\"Test PR AUC: {0}\".format(pr_auc_test))\n      print(\"Train PR AUC: {0}\".format(pr_auc_train))\n\n      print(\"Test MAE: {0}\".format(mae_test))\n      print(\"Train MAE: {0}\".format(mae_train))\n\n\n      mlflow.log_metric('Test residual_std', residual_std_test)\n      mlflow.log_metric('Test y std', y_test_std)\n      mlflow.log_metric('Test shrinking', std_shrinking_test)\n\n      mlflow.log_metric('Train residual std', residual_std_train)\n      mlflow.log_metric('Train y std', y_train_std)\n      mlflow.log_metric('Train shrinking', std_shrinking_train)\n\n      mlflow.log_metric('accuracy_train', accuracy_train)\n      mlflow.log_metric('accuracy_test', accuracy_test)\n\n      mlflow.log_metric('train_pr_auc', pr_auc_train)\n      mlflow.log_metric('test_pr_auc', pr_auc_test)\n\n      mlflow.log_metric('train_roc_auc', roc_auc_train)\n      mlflow.log_metric('test_roc_auc', roc_auc_test)\n      \n      mlflow.log_param(\"clf__boosting_type\", clf__boosting_type)\n      mlflow.log_param(\"clf__learning_rate\", clf__learning_rate)\n      mlflow.log_param(\"clf__num_leaves\", clf__num_leaves)\n      \n  return random_search"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["train_mlflow_randomsearch(features_orig + features_weather + features_supply_demand + features_hist_flf + features_incentive, run_name='orig_weather_supplydemand_histflf_incentive_p2w_random_search')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TerminatedWorkerError</span>                     Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-171461&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>train_mlflow_randomsearch<span class=\"ansiyellow\">(</span>features_orig <span class=\"ansiyellow\">+</span> features_weather <span class=\"ansiyellow\">+</span> features_supply_demand <span class=\"ansiyellow\">+</span> features_hist_flf <span class=\"ansiyellow\">+</span> features_incentive<span class=\"ansiyellow\">,</span> run_name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&apos;orig_weather_supplydemand_histflf_incentive_p2w_random_search&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;command-171460&gt;</span> in <span class=\"ansicyan\">train_mlflow_randomsearch</span><span class=\"ansiblue\">(features, run_name)</span>\n<span class=\"ansigreen\">     35</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     36</span>       random_search <span class=\"ansiyellow\">=</span> RandomizedSearchCV<span class=\"ansiyellow\">(</span>ppl<span class=\"ansiyellow\">,</span> randomParams<span class=\"ansiyellow\">,</span> n_jobs<span class=\"ansiyellow\">=</span><span class=\"ansiyellow\">-</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">,</span> verbose<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">2</span><span class=\"ansiyellow\">,</span> n_iter<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">50</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 37</span><span class=\"ansiyellow\">       </span>random_search<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>X_train<span class=\"ansiyellow\">,</span> y_train<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     38</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     39</span>       y_test_pred <span class=\"ansiyellow\">=</span> random_search<span class=\"ansiyellow\">.</span>predict<span class=\"ansiyellow\">(</span>X_test<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-79c94572-1bd7-41f2-9252-5cff47c539b9/lib/python3.5/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, X, y, groups, **fit_params)</span>\n<span class=\"ansigreen\">    708</span>                 <span class=\"ansigreen\">return</span> results<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    709</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 710</span><span class=\"ansiyellow\">             </span>self<span class=\"ansiyellow\">.</span>_run_search<span class=\"ansiyellow\">(</span>evaluate_candidates<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    711</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    712</span>         <span class=\"ansired\"># For multi-metric evaluation, store the best_index_, best_params_ and</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-79c94572-1bd7-41f2-9252-5cff47c539b9/lib/python3.5/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansicyan\">_run_search</span><span class=\"ansiblue\">(self, evaluate_candidates)</span>\n<span class=\"ansigreen\">   1482</span>         evaluate_candidates(ParameterSampler(\n<span class=\"ansigreen\">   1483</span>             self<span class=\"ansiyellow\">.</span>param_distributions<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>n_iter<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1484</span><span class=\"ansiyellow\">             random_state=self.random_state))\n</span>\n<span class=\"ansigreen\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-79c94572-1bd7-41f2-9252-5cff47c539b9/lib/python3.5/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansicyan\">evaluate_candidates</span><span class=\"ansiblue\">(candidate_params)</span>\n<span class=\"ansigreen\">    687</span>                                <span class=\"ansigreen\">for</span> parameters<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">(</span>train<span class=\"ansiyellow\">,</span> test<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    688</span>                                in product(candidate_params,\n<span class=\"ansigreen\">--&gt; 689</span><span class=\"ansiyellow\">                                           cv.split(X, y, groups)))\n</span><span class=\"ansigreen\">    690</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    691</span>                 <span class=\"ansigreen\">if</span> len<span class=\"ansiyellow\">(</span>out<span class=\"ansiyellow\">)</span> <span class=\"ansiyellow\">&lt;</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-79c94572-1bd7-41f2-9252-5cff47c539b9/lib/python3.5/site-packages/joblib/parallel.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, iterable)</span>\n<span class=\"ansigreen\">   1015</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1016</span>             <span class=\"ansigreen\">with</span> self<span class=\"ansiyellow\">.</span>_backend<span class=\"ansiyellow\">.</span>retrieval_context<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1017</span><span class=\"ansiyellow\">                 </span>self<span class=\"ansiyellow\">.</span>retrieve<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1018</span>             <span class=\"ansired\"># Make sure that we get a last message telling us we are done</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1019</span>             elapsed_time <span class=\"ansiyellow\">=</span> time<span class=\"ansiyellow\">.</span>time<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span> <span class=\"ansiyellow\">-</span> self<span class=\"ansiyellow\">.</span>_start_time<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python3.5/contextlib.py</span> in <span class=\"ansicyan\">__exit__</span><span class=\"ansiblue\">(self, type, value, traceback)</span>\n<span class=\"ansigreen\">     75</span>                 value <span class=\"ansiyellow\">=</span> type<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     76</span>             <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 77</span><span class=\"ansiyellow\">                 </span>self<span class=\"ansiyellow\">.</span>gen<span class=\"ansiyellow\">.</span>throw<span class=\"ansiyellow\">(</span>type<span class=\"ansiyellow\">,</span> value<span class=\"ansiyellow\">,</span> traceback<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     78</span>                 <span class=\"ansigreen\">raise</span> RuntimeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;generator didn&apos;t stop after throw()&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     79</span>             <span class=\"ansigreen\">except</span> StopIteration <span class=\"ansigreen\">as</span> exc<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-79c94572-1bd7-41f2-9252-5cff47c539b9/lib/python3.5/site-packages/joblib/_parallel_backends.py</span> in <span class=\"ansicyan\">retrieval_context</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">    151</span>         tasks<span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    152</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 153</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">yield</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    154</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    155</span>     <span class=\"ansigreen\">def</span> _prepare_worker_env<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> n_jobs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-79c94572-1bd7-41f2-9252-5cff47c539b9/lib/python3.5/site-packages/joblib/parallel.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, iterable)</span>\n<span class=\"ansigreen\">   1015</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1016</span>             <span class=\"ansigreen\">with</span> self<span class=\"ansiyellow\">.</span>_backend<span class=\"ansiyellow\">.</span>retrieval_context<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1017</span><span class=\"ansiyellow\">                 </span>self<span class=\"ansiyellow\">.</span>retrieve<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1018</span>             <span class=\"ansired\"># Make sure that we get a last message telling us we are done</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1019</span>             elapsed_time <span class=\"ansiyellow\">=</span> time<span class=\"ansiyellow\">.</span>time<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span> <span class=\"ansiyellow\">-</span> self<span class=\"ansiyellow\">.</span>_start_time<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-79c94572-1bd7-41f2-9252-5cff47c539b9/lib/python3.5/site-packages/joblib/parallel.py</span> in <span class=\"ansicyan\">retrieve</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">    907</span>             <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    908</span>                 <span class=\"ansigreen\">if</span> getattr<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_backend<span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&apos;supports_timeout&apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansigreen\">False</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 909</span><span class=\"ansiyellow\">                     </span>self<span class=\"ansiyellow\">.</span>_output<span class=\"ansiyellow\">.</span>extend<span class=\"ansiyellow\">(</span>job<span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span>timeout<span class=\"ansiyellow\">=</span>self<span class=\"ansiyellow\">.</span>timeout<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    910</span>                 <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    911</span>                     self<span class=\"ansiyellow\">.</span>_output<span class=\"ansiyellow\">.</span>extend<span class=\"ansiyellow\">(</span>job<span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-79c94572-1bd7-41f2-9252-5cff47c539b9/lib/python3.5/site-packages/joblib/_parallel_backends.py</span> in <span class=\"ansicyan\">wrap_future_result</span><span class=\"ansiblue\">(future, timeout)</span>\n<span class=\"ansigreen\">    560</span>         AsyncResults.get from multiprocessing.&quot;&quot;&quot;\n<span class=\"ansigreen\">    561</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 562</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> future<span class=\"ansiyellow\">.</span>result<span class=\"ansiyellow\">(</span>timeout<span class=\"ansiyellow\">=</span>timeout<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    563</span>         <span class=\"ansigreen\">except</span> LokyTimeoutError<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    564</span>             <span class=\"ansigreen\">raise</span> TimeoutError<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python3.5/concurrent/futures/_base.py</span> in <span class=\"ansicyan\">result</span><span class=\"ansiblue\">(self, timeout)</span>\n<span class=\"ansigreen\">    403</span>                 <span class=\"ansigreen\">raise</span> CancelledError<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    404</span>             <span class=\"ansigreen\">elif</span> self<span class=\"ansiyellow\">.</span>_state <span class=\"ansiyellow\">==</span> FINISHED<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 405</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>__get_result<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    406</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    407</span>                 <span class=\"ansigreen\">raise</span> TimeoutError<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python3.5/concurrent/futures/_base.py</span> in <span class=\"ansicyan\">__get_result</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">    355</span>     <span class=\"ansigreen\">def</span> __get_result<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    356</span>         <span class=\"ansigreen\">if</span> self<span class=\"ansiyellow\">.</span>_exception<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 357</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> self<span class=\"ansiyellow\">.</span>_exception<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    358</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    359</span>             <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_result<span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TerminatedWorkerError</span>: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}</div>"]}}],"execution_count":35},{"cell_type":"code","source":["df.loc[train_index, features].head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div style=\"max-width:1500px;overflow:auto;\">\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day_of_week</th>\n      <th>hour_of_day</th>\n      <th>daypart</th>\n      <th>store_starting_point_id</th>\n      <th>submarket_id</th>\n      <th>window_id</th>\n      <th>hh_temperature</th>\n      <th>hh_apparent_temperature</th>\n      <th>hh_pressure</th>\n      <th>hh_humidity</th>\n      <th>...</th>\n      <th>hh_precip_probability</th>\n      <th>hh_hourly_weather_summary</th>\n      <th>hh_icon</th>\n      <th>pred_demand</th>\n      <th>actual_demand</th>\n      <th>under_predicted_demand</th>\n      <th>pw_hourly_avg_flf</th>\n      <th>pw_hourly_avg_is_flf_above_ideal</th>\n      <th>pw_hourly_avg_is_flf_above_max</th>\n      <th>pw_hourly_avg_dasher_pay_other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>61.81</td>\n      <td>61.81</td>\n      <td>1022.1</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Partly Cloudy</td>\n      <td>partly-cloudy-day</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n      <td>1.764056</td>\n      <td>0.288136</td>\n      <td>0.0</td>\n      <td>35.169492</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>61.81</td>\n      <td>61.81</td>\n      <td>1022.1</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Partly Cloudy</td>\n      <td>partly-cloudy-day</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n      <td>1.764056</td>\n      <td>0.288136</td>\n      <td>0.0</td>\n      <td>35.169492</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>61.81</td>\n      <td>61.81</td>\n      <td>1022.1</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Partly Cloudy</td>\n      <td>partly-cloudy-day</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n      <td>1.764056</td>\n      <td>0.288136</td>\n      <td>0.0</td>\n      <td>35.169492</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>61.81</td>\n      <td>61.81</td>\n      <td>1022.1</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Partly Cloudy</td>\n      <td>partly-cloudy-day</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n      <td>1.764056</td>\n      <td>0.288136</td>\n      <td>0.0</td>\n      <td>35.169492</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>13</td>\n      <td>lunch</td>\n      <td>704</td>\n      <td>78</td>\n      <td>27</td>\n      <td>61.81</td>\n      <td>61.81</td>\n      <td>1022.1</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>Partly Cloudy</td>\n      <td>partly-cloudy-day</td>\n      <td>59.679853</td>\n      <td>71.0</td>\n      <td>11.320147</td>\n      <td>1.764056</td>\n      <td>0.288136</td>\n      <td>0.0</td>\n      <td>35.169492</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["#### random search mlflow customized scoring"],"metadata":{}},{"cell_type":"code","source":["mlflow.set_experiment('/Shared/Experiments/variance_reduction_flf')\n\ndef train_mlflow_randomsearch_scoring(features):\n  with mlflow.start_run(run_name='weather_randomsearch_1'):\n\n      X_train = df.loc[train_index, features]\n      y_train = df.loc[train_index, metrics]\n\n      X_test = df.loc[test_index, features]\n      y_test = df.loc[test_index, metrics]\n\n      print(\"x_train shape\", X_train.shape, 'y_train shape', y_train.shape)\n      print(\"x_test shape\", X_test.shape, 'y_test shape', y_test.shape)\n\n      \n      # target encoding\n      teppl = TargetEncoder(cols=features_target_encode)\n      # clf\n      clfppl = LGBMClassifier()\n\n      # random search\n      # best for orig+weather+supply_demand\n      # {'clf__boosting_type': 'gbdt', 'clf__learning_rate': 0.10799590819985533, 'clf__num_leaves': 476}\n      # {'clf__boosting_type': 'gbdt', 'clf__learning_rate': 0.10442678580364907, 'clf__num_leaves': 411} +weather\n      # {'clf__boosting_type': 'gbdt', 'clf__learning_rate': 0.08908617527882136, 'clf__num_leaves': 491} +weather+supply/demand\n      \n      randomParams = {\n          'clf__learning_rate': stats.uniform(0.01, 0.1), \n          'clf__num_leaves': stats.randint(16, 512),\n          'clf__boosting_type' : ['gbdt', 'dart', 'goss']    \n      }\n      \n      #new scoring function\n#     def custom_loss_func_est(estimator, X_train, y_train):\n#         y_pred = estimator.predict_proba(X_train)[:, 1]\n#         df_y_pred = pd.DataFrame(data=y_pred, columns=['pred_proba'])\n#         df_tmp = pd.concat([X_train, y_train, df_y_pred], axis=1, sort=False)\n#         res = pg.partial_corr(data=df_tmp, x='pred_proba', y=metrics, covar=['submarket_id', 'pw_hourly_avg_is_flf_above_ideal']).round(3)\n#         return abs(res['r'].values[0])\n\n#     custom_scorer_partial_corr = make_scorer(custom_loss_func_est, greater_is_better=True)\n    \n      def my_scorer(estimator, xx_train, yy_true):\n        covar = ['pw_hourly_avg_is_flf_above_ideal', 'pw_hourly_avg_flf']\n        yy_pred = estimator.predict_proba(xx_train)[:, 1]\n        df_y_pred = pd.DataFrame(data=yy_pred, columns=['pred_proba'])\n        df_yy_true = pd.DataFrame(data=yy_true.values, columns=['label'])\n       \n        df_tmp = pd.concat([xx_train[covar], df_yy_true, df_y_pred], axis=1, sort=False)\n#         print(xx_train.head(5))\n#         print(df_yy_true.head(5))\n#         print(df_y_pred.head(5))                                                    \n        print(df_tmp.head(100))\n                                                    \n        res = pg.partial_corr(data=df_tmp, x='pred_proba', y='label', covar=covar).round(1) #3\n        return abs(res['r'].values[0])\n  \n      \n      ppl = Pipeline([('target_encode', teppl), ('clf', clfppl)])\n\n      random_search = RandomizedSearchCV(ppl, randomParams, n_jobs=-1, verbose=2, n_iter=50, scoring=my_scorer)\n      random_search.fit(X_train, y_train)\n      \n      y_test_pred = random_search.predict(X_test)\n      y_test_pred_proba = random_search.predict_proba(X_test)[:,1]\n\n      y_train_pred = random_search.predict(X_train)\n      y_train_pred_proba = random_search.predict_proba(X_train)[:,1]\n\n      std_shrinking_test, std_shrinking_train, \\\n           residual_std_test, y_test_std, residual_std_train, y_train_std, \\\n           accuracy_test, roc_auc_test, pr_auc_test, log_loss_test, mae_test, \\\n           accuracy_train, roc_auc_train, pr_auc_train, log_loss_train, mae_train = eval_model(y_train, y_train_pred, y_train_pred_proba, y_test, y_test_pred, y_test_pred_proba)\n\n      mlflow.set_tag('features', features)\n\n      print(\"Test Log Loss: {0}\".format(log_loss_test))\n      print(\"Train Log Loss: {0}\".format(log_loss_train))\n\n      print(\"Test Accuracy Score: {0}\".format(accuracy_test))\n      print(\"Train Accuracy Score: {0}\".format(accuracy_train))\n\n      print(\"Test ROC AUC: {0}\".format(roc_auc_test))\n      print(\"Train ROC AUC: {0}\".format(roc_auc_train))\n\n      print(\"Test PR AUC: {0}\".format(pr_auc_test))\n      print(\"Train PR AUC: {0}\".format(pr_auc_train))\n\n      print(\"Test MAE: {0}\".format(mae_test))\n      print(\"Train MAE: {0}\".format(mae_train))\n\n\n      mlflow.log_metric('Test residual_std', residual_std_test)\n      mlflow.log_metric('Test y std', y_test_std)\n      mlflow.log_metric('Test shrinking', std_shrinking_test)\n\n      mlflow.log_metric('Train residual std', residual_std_train)\n      mlflow.log_metric('Train y std', y_train_std)\n      mlflow.log_metric('Train shrinking', std_shrinking_train)\n\n\n      mlflow.log_metric('accuracy_train', accuracy_train)\n      mlflow.log_metric('accuracy_test', accuracy_test)\n\n      mlflow.log_metric('train_pr_auc', pr_auc_train)\n      mlflow.log_metric('test_pr_auc', pr_auc_test)\n\n      mlflow.log_metric('train_roc_auc', roc_auc_train)\n      mlflow.log_metric('test_roc_auc', roc_auc_test)\n      \n      mlflow.log_parameter(\"clf__boosting_type\", clf__boosting_type)\n      mlflow.log_parameter(\"clf__learning_rate\", clf__learning_rate)\n      mlflow.log_parameter(\"clf__num_leaves\", clf__num_leaves)\n      \n      print(random_search.best_params_)\n  return random_search"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"code","source":["# train_mlflow_randomsearch(features_orig)\n# train_mlflow_randomsearch(features_orig + features_weather)\n# train_mlflow_randomsearch(features_orig + features_supply_demand)\nrandom_search = train_mlflow_randomsearch(features_orig + features_weather + features_supply_demand + features_hist_flf + features_incentive)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">_RemoteTraceback</span>                          Traceback (most recent call last)\n<span class=\"ansi-red-fg\">_RemoteTraceback</span>: \n&#34;&#34;&#34;\nTraceback (most recent call last):\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py&#34;, line 431, in _process_worker\n    r = call_item()\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py&#34;, line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/joblib/_parallel_backends.py&#34;, line 593, in __call__\n    return self.func(*args, **kwargs)\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/joblib/parallel.py&#34;, line 253, in __call__\n    for func, args, kwargs in self.items]\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/joblib/parallel.py&#34;, line 253, in &lt;listcomp&gt;\n    for func, args, kwargs in self.items]\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/sklearn/model_selection/_validation.py&#34;, line 544, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/sklearn/model_selection/_validation.py&#34;, line 591, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/sklearn/metrics/_scorer.py&#34;, line 89, in __call__\n    score = scorer(estimator, *args, **kwargs)\n  File &#34;&lt;command-169831&gt;&#34;, line 55, in my_scorer\n  File &#34;/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/pingouin/correlation.py&#34;, line 639, in partial_corr\n    assert data.shape[0] &gt; 2, &#39;Data must have at least 3 non-NAN samples.&#39;\nAssertionError: Data must have at least 3 non-NAN samples.\n&#34;&#34;&#34;\n\nThe above exception was the direct cause of the following exception:\n\n<span class=\"ansi-red-fg\">AssertionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-169832&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-red-fg\"># train_mlflow_randomsearch(features_orig + features_weather)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-red-fg\"># train_mlflow_randomsearch(features_orig + features_supply_demand)</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span>random_search <span class=\"ansi-blue-fg\">=</span> train_mlflow_randomsearch<span class=\"ansi-blue-fg\">(</span>features_orig <span class=\"ansi-blue-fg\">+</span> features_weather <span class=\"ansi-blue-fg\">+</span> features_supply_demand <span class=\"ansi-blue-fg\">+</span> features_hist_flf <span class=\"ansi-blue-fg\">+</span> features_incentive<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-169831&gt;</span> in <span class=\"ansi-cyan-fg\">train_mlflow_randomsearch</span><span class=\"ansi-blue-fg\">(features)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     60</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>       random_search <span class=\"ansi-blue-fg\">=</span> RandomizedSearchCV<span class=\"ansi-blue-fg\">(</span>ppl<span class=\"ansi-blue-fg\">,</span> randomParams<span class=\"ansi-blue-fg\">,</span> n_jobs<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> verbose<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> n_iter<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">50</span><span class=\"ansi-blue-fg\">,</span> scoring<span class=\"ansi-blue-fg\">=</span>my_scorer<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 62</span><span class=\"ansi-red-fg\">       </span>random_search<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X_train<span class=\"ansi-blue-fg\">,</span> y_train<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     63</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>       y_test_pred <span class=\"ansi-blue-fg\">=</span> random_search<span class=\"ansi-blue-fg\">.</span>predict<span class=\"ansi-blue-fg\">(</span>X_test<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, groups, **fit_params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    708</span>                 <span class=\"ansi-green-fg\">return</span> results\n<span class=\"ansi-green-intense-fg ansi-bold\">    709</span> \n<span class=\"ansi-green-fg\">--&gt; 710</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>_run_search<span class=\"ansi-blue-fg\">(</span>evaluate_candidates<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    711</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    712</span>         <span class=\"ansi-red-fg\"># For multi-metric evaluation, store the best_index_, best_params_ and</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansi-cyan-fg\">_run_search</span><span class=\"ansi-blue-fg\">(self, evaluate_candidates)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1482</span>         evaluate_candidates(ParameterSampler(\n<span class=\"ansi-green-intense-fg ansi-bold\">   1483</span>             self<span class=\"ansi-blue-fg\">.</span>param_distributions<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>n_iter<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">-&gt; 1484</span><span class=\"ansi-red-fg\">             random_state=self.random_state))\n</span>\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansi-cyan-fg\">evaluate_candidates</span><span class=\"ansi-blue-fg\">(candidate_params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    687</span>                                <span class=\"ansi-green-fg\">for</span> parameters<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>train<span class=\"ansi-blue-fg\">,</span> test<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    688</span>                                in product(candidate_params,\n<span class=\"ansi-green-fg\">--&gt; 689</span><span class=\"ansi-red-fg\">                                           cv.split(X, y, groups)))\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    690</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    691</span>                 <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>out<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&lt;</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/joblib/parallel.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, iterable)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1040</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1041</span>             <span class=\"ansi-green-fg\">with</span> self<span class=\"ansi-blue-fg\">.</span>_backend<span class=\"ansi-blue-fg\">.</span>retrieval_context<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1042</span><span class=\"ansi-red-fg\">                 </span>self<span class=\"ansi-blue-fg\">.</span>retrieve<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1043</span>             <span class=\"ansi-red-fg\"># Make sure that we get a last message telling us we are done</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1044</span>             elapsed_time <span class=\"ansi-blue-fg\">=</span> time<span class=\"ansi-blue-fg\">.</span>time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-</span> self<span class=\"ansi-blue-fg\">.</span>_start_time\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/joblib/parallel.py</span> in <span class=\"ansi-cyan-fg\">retrieve</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    919</span>             <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    920</span>                 <span class=\"ansi-green-fg\">if</span> getattr<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_backend<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;supports_timeout&#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 921</span><span class=\"ansi-red-fg\">                     </span>self<span class=\"ansi-blue-fg\">.</span>_output<span class=\"ansi-blue-fg\">.</span>extend<span class=\"ansi-blue-fg\">(</span>job<span class=\"ansi-blue-fg\">.</span>get<span class=\"ansi-blue-fg\">(</span>timeout<span class=\"ansi-blue-fg\">=</span>self<span class=\"ansi-blue-fg\">.</span>timeout<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    922</span>                 <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    923</span>                     self<span class=\"ansi-blue-fg\">.</span>_output<span class=\"ansi-blue-fg\">.</span>extend<span class=\"ansi-blue-fg\">(</span>job<span class=\"ansi-blue-fg\">.</span>get<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-d0f2420c-6167-48df-a0bc-eec45cf62acb/lib/python3.7/site-packages/joblib/_parallel_backends.py</span> in <span class=\"ansi-cyan-fg\">wrap_future_result</span><span class=\"ansi-blue-fg\">(future, timeout)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    538</span>         AsyncResults.get from multiprocessing.&#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">    539</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 540</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> future<span class=\"ansi-blue-fg\">.</span>result<span class=\"ansi-blue-fg\">(</span>timeout<span class=\"ansi-blue-fg\">=</span>timeout<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    541</span>         <span class=\"ansi-green-fg\">except</span> CfTimeoutError<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    542</span>             <span class=\"ansi-green-fg\">raise</span> TimeoutError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/usr/lib/python3.7/concurrent/futures/_base.py</span> in <span class=\"ansi-cyan-fg\">result</span><span class=\"ansi-blue-fg\">(self, timeout)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    430</span>                 <span class=\"ansi-green-fg\">raise</span> CancelledError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    431</span>             <span class=\"ansi-green-fg\">elif</span> self<span class=\"ansi-blue-fg\">.</span>_state <span class=\"ansi-blue-fg\">==</span> FINISHED<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 432</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>__get_result<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    433</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    434</span>                 <span class=\"ansi-green-fg\">raise</span> TimeoutError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/usr/lib/python3.7/concurrent/futures/_base.py</span> in <span class=\"ansi-cyan-fg\">__get_result</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    382</span>     <span class=\"ansi-green-fg\">def</span> __get_result<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    383</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>_exception<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 384</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">raise</span> self<span class=\"ansi-blue-fg\">.</span>_exception\n<span class=\"ansi-green-intense-fg ansi-bold\">    385</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    386</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_result\n\n<span class=\"ansi-red-fg\">AssertionError</span>: Data must have at least 3 non-NAN samples.</div>"]}}],"execution_count":39},{"cell_type":"code","source":["X_test = df.loc[test_index, features]\ny_test = df.loc[test_index, metrics]\ny_test_pred_prob = random_search.predict_proba(X_test)[:, 1]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-169833&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> X_test <span class=\"ansiyellow\">=</span> df<span class=\"ansiyellow\">.</span>loc<span class=\"ansiyellow\">[</span>test_index<span class=\"ansiyellow\">,</span> features<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> y_test <span class=\"ansiyellow\">=</span> df<span class=\"ansiyellow\">.</span>loc<span class=\"ansiyellow\">[</span>test_index<span class=\"ansiyellow\">,</span> metrics<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>y_test_pred_prob <span class=\"ansiyellow\">=</span> random_search<span class=\"ansiyellow\">.</span>predict_proba<span class=\"ansiyellow\">(</span>X_test<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;random_search&apos; is not defined</div>"]}}],"execution_count":40},{"cell_type":"code","source":["y_test_pred_prob.shape, X_test.shape\ntest_result = df.loc[test_index].copy()\ntest_result['pred_prob'] = y_test_pred_prob\nprint(test_result.head(5))\ntest_result.to_csv('/dbfs/chizhang/variance_reduction/result/test_result_weather_supply_demand.csv')"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["test_result = pd.read_csv('/dbfs/chizhang/variance_reduction/result/test_result_weather_supply_demand.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"code","source":["metrics = ['is_flf_above_ideal']\ntest_result['pred_prob'].std(), test_result['is_flf_above_ideal'].std()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: (0.18630403969930892, 0.3783979991160973)</div>"]}}],"execution_count":43},{"cell_type":"code","source":["(test_result['pred_prob'] - test_result['is_flf_above_ideal']).std()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: 0.3428744368825526</div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["#### random search"],"metadata":{}},{"cell_type":"code","source":["# target encoding\nteppl = TargetEncoder(cols=features_target_encode)\n# clf\nclfppl = LGBMClassifier()\n\n# random search\nrandomParams = {\n    'clf__learning_rate': stats.uniform(0.01, 0.1), \n    'clf__num_leaves': stats.randint(16, 512),\n    'clf__boosting_type' : ['gbdt', 'dart', 'goss']    \n}\n\nppl = Pipeline([('target_encode', teppl), ('clf', clfppl)])\n\nrandom_search = RandomizedSearchCV(ppl, randomParams, n_jobs=-1, verbose=2, n_iter=100)\nrandom_search.fit(X_train, y_train)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["random_search.best_params_"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["ppl_best = random_search.best_estimator_"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":["#### best model after randome search"],"metadata":{}},{"cell_type":"code","source":["teppl = TargetEncoder(cols=features_target_encode)\n\nclfppl = LGBMClassifier()\n\nppl_best = Pipeline([('target_encode', teppl), ('clf', clfppl)])\nppl_best.set_params(clf__learning_rate=0.09985392034627226, clf__boosting_type='gbdt', clf__num_leaves=486)\n\n\nX_train = df.loc[train_index, features]\ny_train = df.loc[train_index, metrics]\n\nX_test = df.loc[test_index, features]\ny_test = df.loc[test_index, metrics]\n\n      \nppl_best.fit(X_train, y_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">20</span><span class=\"ansired\">]: </span>Pipeline(steps=[(&apos;target_encode&apos;, TargetEncoder(cols=[&apos;store_starting_point_id&apos;, &apos;submarket_id&apos;, &apos;window_id&apos;],\n       drop_invariant=False, handle_missing=&apos;value&apos;,\n       handle_unknown=&apos;value&apos;, min_samples_leaf=1, return_df=True,\n       smoothing=1.0, verbose=0)), (&apos;clf&apos;, LGBMClassifier(boosting_type=&apos;gbdt&apos;...ambda=0.0,\n        silent=True, subsample=1.0, subsample_for_bin=200000,\n        subsample_freq=0))])</div>"]}}],"execution_count":50},{"cell_type":"markdown","source":["#### clf vanilla"],"metadata":{}},{"cell_type":"code","source":["mlflow.set_experiment('/Shared/Experiments/variance_reduction_flf')\n\ndef train_mlflow(features, run_name):\n  with mlflow.start_run(run_name=run_name):\n\n      X_train = df.loc[train_index, features]\n      y_train = df.loc[train_index, metrics]\n\n      X_test = df.loc[test_index, features]\n      y_test = df.loc[test_index, metrics]\n\n      print(\"x_train shape\", X_train.shape, 'y_train shape', y_train.shape)\n      print(\"x_test shape\", X_test.shape, 'y_test shape', y_test.shape)\n\n      teppl_vanilla = TargetEncoder(cols=features_target_encode)\n      clfppl_vanilla = LGBMClassifier()\n\n      ppl_vanilla = Pipeline([('target_encode_vanilla', teppl_vanilla), ('clf_vanilla', clfppl_vanilla)])\n\n      ppl_vanilla.fit(X_train, y_train)\n\n      y_test_pred = ppl_vanilla.predict(X_test)\n      y_test_pred_proba = ppl_vanilla.predict_proba(X_test)[:,1]\n\n      y_train_pred = ppl_vanilla.predict(X_train)\n      y_train_pred_proba = ppl_vanilla.predict_proba(X_train)[:,1]\n\n      \n      # save to csv\n      test_result = df.loc[test_index].copy()\n      test_result['pred_prob'] = y_test_pred_proba\n      print(test_result.head(5))\n      test_result.to_csv('/dbfs/chizhang/variance_reduction/result/test_result_'+ run_name+ '_0610.csv')\n      \n      std_shrinking_test, std_shrinking_train, \\\n           residual_std_test, y_test_std, residual_std_train, y_train_std, \\\n           accuracy_test, roc_auc_test, pr_auc_test, log_loss_test, mae_test, \\\n           accuracy_train, roc_auc_train, pr_auc_train, log_loss_train, mae_train = eval_model(y_train, y_train_pred, y_train_pred_proba, y_test, y_test_pred, y_test_pred_proba)\n\n      mlflow.set_tag('features', features)\n\n      print(\"Test Log Loss: {0}\".format(log_loss_test))\n      print(\"Train Log Loss: {0}\".format(log_loss_train))\n\n      print(\"Test Accuracy Score: {0}\".format(accuracy_test))\n      print(\"Train Accuracy Score: {0}\".format(accuracy_train))\n\n\n      print(\"Test ROC AUC: {0}\".format(roc_auc_test))\n      print(\"Train ROC AUC: {0}\".format(roc_auc_train))\n\n      print(\"Test PR AUC: {0}\".format(pr_auc_test))\n      print(\"Train PR AUC: {0}\".format(pr_auc_train))\n\n      print(\"Test MAE: {0}\".format(mae_test))\n      print(\"Train MAE: {0}\".format(mae_train))\n\n      mlflow.log_metric('Test residual_std', residual_std_test)\n      mlflow.log_metric('Test y std', y_test_std)\n      mlflow.log_metric('Test shrinking', std_shrinking_test)\n\n      mlflow.log_metric('Train residual std', residual_std_train)\n      mlflow.log_metric('Train y std', y_train_std)\n      mlflow.log_metric('Train shrinking', std_shrinking_train)\n\n\n      mlflow.log_metric('accuracy_train', accuracy_train)\n      mlflow.log_metric('accuracy_test', accuracy_test)\n\n      mlflow.log_metric('train_pr_auc', pr_auc_train)\n      mlflow.log_metric('test_pr_auc', pr_auc_test)\n\n      mlflow.log_metric('train_roc_auc', roc_auc_train)\n      mlflow.log_metric('test_roc_auc', roc_auc_test)\n      \n  return ppl_vanilla"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"code","source":["# train_mlflow(features_orig)\n# train_mlflow(features_orig + features_weather)\n# train_mlflow(features_orig + features_supply_demand)\n# train_mlflow(features_orig + features_weather + features_supply_demand)\nppl_vanilla = train_mlflow(features_orig + features_weather + features_supply_demand + features_hist_flf + features_incentive, run_name='orig_weather_supplydemand_histflf_incentive_p1w')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">x_train shape (8745379, 25) y_train shape (8745379,)\nx_test shape (2896477, 25) y_test shape (2896477,)\n/local_disk0/pythonVirtualEnvDirs/virtualEnv-5eaa5bd1-eded-41c6-8aac-6a40c293e8bd/lib/python3.5/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use &#96;array.size &gt; 0&#96; to check that an array is not empty.\n  if diff:\n/local_disk0/pythonVirtualEnvDirs/virtualEnv-5eaa5bd1-eded-41c6-8aac-6a40c293e8bd/lib/python3.5/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use &#96;array.size &gt; 0&#96; to check that an array is not empty.\n  if diff:\n      unnamed: 0                 created_at  delivery_id day_of_week  \\\n1581        1581 2020-05-29 11:43:03.189071    638041813           5   \n1582        1582 2020-05-29 11:58:43.382475    638045930           5   \n1583        1583 2020-05-29 11:57:54.267532    638045700           5   \n1584        1584 2020-05-29 11:00:08.028520    638033149           5   \n1585        1585 2020-05-29 11:27:46.033317    638038349           5   \n\n     hour_of_day    daypart store_starting_point_id submarket_id window_id  \\\n1581           7  breakfast                    6925           23        15   \n1582           7  breakfast                    6925           23        15   \n1583          21  latenight                    5997         2279        43   \n1584          21  latenight                    5997         2279        42   \n1585          21  latenight                    5997         2279        42   \n\n      is_flf_above_ideal    ...      hh_cloud_cover  hh_dewpoint  \\\n1581                   1    ...                0.78        67.14   \n1582                   1    ...                0.78        67.14   \n1583                   0    ...                0.22         7.88   \n1584                   0    ...                0.22         7.88   \n1585                   0    ...                0.22         7.88   \n\n      hh_hourly_weather_summary  hh_precip_intensity  hh_precip_probability  \\\n1581           Possible Drizzle               0.0044                   0.47   \n1582           Possible Drizzle               0.0044                   0.47   \n1583                      Clear               0.0000                   0.00   \n1584                      Clear               0.0000                   0.00   \n1585                      Clear               0.0000                   0.00   \n\n          hh_icon  pred_demand  actual_demand  under_predicted_demand  \\\n1581         rain     5.464871            6.0                0.535129   \n1582         rain     5.464871            6.0                0.535129   \n1583  clear-night    10.050102            7.0               -3.050102   \n1584  clear-night    18.631689           14.0               -4.631689   \n1585  clear-night    18.631689           14.0               -4.631689   \n\n      pred_prob  \n1581   0.207313  \n1582   0.207313  \n1583   0.011030  \n1584   0.014190  \n1585   0.014190  \n\n[5 rows x 30 columns]\nin y_train, pct of ones 0.23195392675377477 pct of zeros 0.7680460732462252\nin y_test, pct of ones 0.17666254556828864 pct of zeros 0.8233374544317114\nTest Log Loss: 0.36791642270654373\nTrain Log Loss: 0.3860038261985371\nTest Accuracy Score: 0.8429191738791643\nTrain Accuracy Score: 0.8249996941241768\nTest ROC AUC: 0.8097484420349478\nTrain ROC AUC: 0.8498189543625759\nTest PR AUC: 0.5155636143779397\nTrain PR AUC: 0.6309484642903571\nTest MAE: 0.15708082612083576\nTrain MAE: 0.1750003058758231\n</div>"]}}],"execution_count":53},{"cell_type":"code","source":["with open('/dbfs/chizhang/variance_reduction/model/071520_flf_prediction_variance_reduction_ppl.dill', 'wb') as f:\n  dill.dump(ppl_vanilla, f)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"markdown","source":["### Testing"],"metadata":{}},{"cell_type":"code","source":["residual_std_m1, y_std = eval_model(ppl_best, X_test, y_test)"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["### Important features"],"metadata":{}},{"cell_type":"code","source":["dictionary = dict(zip(features, ppl_best['clf'].feature_importances_))\n\ndictionary = {k: v for k, v in sorted(dictionary.items(), key=lambda item: item[1])}\n\n# dictionary = sorted(dictionary.items(), key=operator.itemgetter(1))\nprint(dictionary)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["with open('/dbfs/chizhang/variance_reduction/model/061520_flf_prediction_variance_reduction_ppl.dill', 'wb') as f:\n  dill.dump(ppl_best, f)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"code","source":["##### END ####\n\n\n\n\n\n\n"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["## validate correlation in unit level"],"metadata":{}},{"cell_type":"code","source":["with open('/dbfs/chizhang/variance_reduction/model/051620_flf_prediction_variance_reduction_ppl.dill', 'rb') as f:\n  ppl_best = dill.load(f)"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["for f in ['store_starting_point_id', 'submarket_id', 'window_id']:\n  print('feature', f)\n  print('\\tTrain PearsonrResult', pearsonr(ppl_best.named_steps[\"target_encode\"].transform(X_test)[f].values, y_test.values.reshape(len(y_test), )))"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["df.groupby(['store_starting_point_id', 'daypart']).agg({'is_flf_above_ideal' : 'mean'})"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"markdown","source":["## Model training"],"metadata":{}},{"cell_type":"code","source":["# # features_high_corr = ['STORE_STARTING_POINT_ID', 'SUBMARKET_ID', 'hour_of_day', 'day_of_week'] #better residual std without day_of_week\n\n# features_high_corr = features\n# #model 1: default with balancing\n# clf_default_is_unbalanced = LGBMClassifier(is_unbalance =True)#is_unbalance =True\n# clf_default_is_unbalanced.fit(X_train_encoded[features_high_corr], y_train)\n\n# #model 2: default\n# clf_default = LGBMClassifier()\n# clf_default.fit(X_train_encoded[features_high_corr], y_train)"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["# # model 3: grid search\n# gridParams = {\n#     'learning_rate': [0.01, 0.05, 0.1],\n#     'num_leaves': [16, 31, 64, 128],\n#     'boosting_type' : ['gbdt', 'dart', 'goss'],\n#     'objective' : ['binary'],\n#     'max_depth' : [-1, 5, 10],\n# #     'random_state' : [501], \n# #     'colsample_bytree' : [0.5,0.7],\n# #     'subsample' : [0.5,0.7],\n# #     'min_split_gain' : [0.01],\n#     'min_data_in_leaf':[5, 10, 20],\n# #     'metric':['auc']\n#     }\n# #{'boosting_type': 'goss', 'objective': 'binary', 'learning_rate': 0.1, 'num_leaves': 64, 'max_depth': -1}\n\n# clf_tuned = LGBMClassifier()\n# grid = GridSearchCV(clf_tuned, gridParams,verbose=2, n_jobs=-1)\n# grid.fit(X_train_encoded[features_high_corr], y_train)\n\n# # print(grid.best_score_)\n# print(grid.best_params_)\n"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["# # model 4: random search\n# import scipy.stats as stats\n# randomParams = {\n#     'learning_rate': stats.uniform(0.01, 0.1), \n#     'num_leaves': stats.randint(16, 256),\n#     'boosting_type' : ['gbdt', 'dart', 'goss'],\n#     'objective' : ['binary'],\n#     'max_depth' : [-1, 5, 10],\n# #     'random_state' : [501], \n# #     'colsample_bytree' : [0.5,0.7],\n# #     'subsample' : [0.5,0.7],\n# #     'min_split_gain' : [0.01],\n# #     'min_data_in_leaf':[10],\n# #     'metric':['auc']\n#     }\n# #{'boosting_type': 'goss', 'objective': 'binary', 'learning_rate': 0.1, 'num_leaves': 64, 'max_depth': -1}\n\n# clf_tuned_random = LGBMClassifier()\n# model_random_search = RandomizedSearchCV(clf_tuned_random, randomParams, verbose=2, n_jobs=-1, n_iter=100)\n# model_random_search.fit(X_train_encoded[features_high_corr], y_train)\n\n# # print(grid.best_score_)\n# print(model_random_search.best_params_)\n"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":["## Testing"],"metadata":{}},{"cell_type":"code","source":["residual_std_m1, _ = eval_model(clf_default_is_unbalanced, X_test_encoded[features_high_corr], y_test)"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["residual_std_m2, _ = eval_model(clf_default, X_test_encoded[features_high_corr], y_test)"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":["residual_std_m3, _ = eval_model(grid, X_test_encoded[features_high_corr], y_test)"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"code","source":["residual_std_m4, y_std = eval_model(model_random_search, X_test_encoded[features_high_corr], y_test)"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":["## Result plotting"],"metadata":{}},{"cell_type":"code","source":["from matplotlib import pyplot as plt\nimport matplotlib.ticker as mtick\n\n# plot 4 model performance\n# std_clf_is_unbalanced = 0.4239141851690449\n# std_clf_default = 0.422724398281608\n# std_grid_search = 0.4211761747709921\n# std_random_search = 0.42077421076528226\n# std_random_search_new = 0.4200526230592615 #new features\n# std_testing_data = 0.4555727985659514\n\nstd_testing_data = y_std\n\nstd_clf_is_unbalanced = residual_std_m1\nstd_clf_default = residual_std_m2\nstd_grid_search = residual_std_m3\nstd_random_search = residual_std_m4\n\nheights = [std_testing_data, std_clf_is_unbalanced, std_clf_default, std_grid_search, std_random_search]\nheights =[i for i in heights]\nheights_pct = [1 - i/std_testing_data for i in heights]\nfig, ax = plt.subplots(figsize=(8, 6))\nax.bar(range(len(heights)), heights)\nax.set_ylabel('STD')\n\nplt.xticks(range(len(heights)), ['y std', 'residual_m1 (w/ balancing)', 'residual_m2(w/o balancing)', 'residual_m3(w/ grid search)', 'residual_m4(w/ random search)'])\nplt.xticks(rotation=10)\nax2 = ax.twinx()\nax2.plot(heights_pct, '-o', color='black')\nax2.set_ylabel('% of STD Reduction')\n\nvals = ax2.get_yticks()\nax2.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n\nfor i,j in zip(range(len(heights_pct)), heights_pct):\n    ax2.annotate('{:,.2%}'.format(j),xy=(i,j))\nplt.grid()\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["\n\n\n\n\n\n\n\n\n\n\n"],"metadata":{},"outputs":[],"execution_count":78}],"metadata":{"name":"variance_reduction_v6_etl_live","notebookId":169797},"nbformat":4,"nbformat_minor":0}
